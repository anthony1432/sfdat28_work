{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#time to cluster my data into groups to find out if anything meaningful can come from it.\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.io.json import json_normalize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline, make_union\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load beer data set\n",
    "beer_train = pd.read_csv('beer_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beer_train.rename(columns = {'id':'beer_id'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set the features to create clusters from\n",
    "X = beer_train[beer_train['loc_country_code'] == 840][['ibu_x',\n",
    "                                                       'abv_x',\n",
    "                                                       'originalGravity_x',\n",
    "                                                       'srmId_x',\n",
    "                                                       'hop_alphaacid',\n",
    "                                                       'hop_betaacid',\n",
    "                                                       'hop_caryophyllene',\n",
    "                                                       'hop_myrcene',\n",
    "                                                       'hop_humulene',\n",
    "                                                       'hop_cohumulone',\n",
    "                                                       'hop_geraniol',\n",
    "                                                       'hop_totaloil'\n",
    "                                                      ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test to see how many clusters will be best based on silhouette score\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "k_range = range(2, 20)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km.fit(X_scaled)\n",
    "    scores.append(metrics.silhouette_score(X_scaled, km.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot results to see best cluster number visually\n",
    "plt.plot(k_range, scores)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Coefficient')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create clusters only for beers from the US(country code 840)\n",
    "beers_US_hops = beer_train[beer_train['loc_country_code']==840]\n",
    "scaler = StandardScaler()\n",
    "X4_scaled = scaler.fit_transform(X4)\n",
    "km = KMeans(n_clusters=12, random_state=1)\n",
    "km.fit(X4_scaled)\n",
    "beers_US_hops['cluster'] = km.labels_\n",
    "beers_US_hops.groupby('cluster').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the results\n",
    "beers_US_hops.to_csv('beers_US_hops.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#explore the clusters\n",
    "beers_US_hops.groupby('cluster').style_name_x.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beers_US_hops[beers_US_hops['cluster'] == 0][['abv_x','ibu_x','originalGravity_x','srmId_x']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beers_US_hops[beers_US_hops['cluster'] == 1][['abv_x','ibu_x','originalGravity_x','srmId_x']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beers_US_hops[beers_US_hops['cluster'] == 2][['abv_x','ibu_x','originalGravity_x','srmId_x']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beers_US_hops[beers_US_hops['cluster'] == 3][['abv_x','ibu_x','originalGravity_x','srmId_x']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beers_US_hops[beers_US_hops['cluster'] == 4][['abv_x','ibu_x','originalGravity_x','srmId_x']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beers_US_hops[beers_US_hops['cluster'] == 5][['abv_x','ibu_x','originalGravity_x','srmId_x']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beers_US_hops[beers_US_hops['cluster'] == 6][['abv_x','ibu_x','originalGravity_x','srmId_x']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beers_US_hops[beers_US_hops['cluster'] == 7][['abv_x','ibu_x','originalGravity_x','srmId_x']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beers_US_hops[beers_US_hops['cluster'] == 8][['abv_x','ibu_x','originalGravity_x','srmId_x']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beers_US_hops[beers_US_hops['cluster'] == 9][['abv_x','ibu_x','originalGravity_x','srmId_x']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beers_US_hops[beers_US_hops['cluster'] == 10][['abv_x','ibu_x','originalGravity_x','srmId_x']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beers_US_hops[beers_US_hops['cluster'] == 11][['abv_x','ibu_x','originalGravity_x','srmId_x']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I now want to see which hops should be used to create a beer with my desired characteristics. \n",
    "#To do that I will fit a prediciton model to output a target cluster nubmer and then check the most common hops for that cluster.\n",
    "X,y = beers_US_hops[['abv_x','ibu_x','originalGravity_x','styleId_x','srmId_x']],beers_US_hops['cluster']\n",
    "\n",
    "print X.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test accuracy of KNN.  This wasn't very good.\n",
    "scores = []\n",
    "for i in range(1, 30):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X, y)\n",
    "    scores.append(knn.score(X, y))\n",
    "    \n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test accuacry of a RandomForestClassifier.  This was a much better result.\n",
    "scores = []\n",
    "for i in range(1, 100):\n",
    "    rf = RandomForestClassifier(n_estimators = i)\n",
    "    rf.fit(X,y)\n",
    "    scores.append(rf.score(X, y))\n",
    "    \n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1,100), scores)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_estimators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#maybe I can do better by using many models at the same time and taking the best restult.  I will do this with a VotingClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [('rf', RandomForestClassifier(n_estimators=15)),\n",
    "          ('decision', DecisionTreeClassifier(max_depth=5, max_features = 4)),\n",
    "          ('NB', MultinomialNB()),\n",
    "          ('log', LogisticRegression())\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vc = VotingClassifier(models)\n",
    "params = {'voting':['soft', 'hard']}\n",
    "grid = GridSearchCV(vc, params, cv=5, scoring='accuracy')\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this model did better so I will use it.\n",
    "print grid.best_score_\n",
    "print grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit the model to my data and create a variable of the predicted cluster.\n",
    "new_test2 = [7,60,1.080,127,15]\n",
    "model1 = RandomForestClassifier(n_estimators=16)\n",
    "model2 = DecisionTreeClassifier(max_depth=4, max_features = 4)\n",
    "model3 = MultinomialNB()\n",
    "model4 = LogisticRegression()\n",
    "vc = VotingClassifier(estimators = [('rf',model1),('dt', model2),('nb',model3),('log',model4)], voting = 'soft')\n",
    "vc.fit(X,y)\n",
    "probabs = vc.predict(new_test2)\n",
    "cluster_ing = np.where(probabs == probabs.max())\n",
    "print cluster_ing\n",
    "print int(probabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#take the predicted cluster and show the most common hops used in that cluster.\n",
    "print beers_US_hops.groupby(beers_US_hops['cluster'] == int(probabs)).hop_names.value_counts()[1].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:playtime]",
   "language": "python",
   "name": "conda-env-playtime-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
